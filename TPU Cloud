Using TPU VM Clound
Approach 1. gcloud  commanc

A. First, create instance
gcloud compute tpus tpu-vm create lean-column \
--zone=europe-west4-a \
--accelerator-type=v3-8 \
--version=tpu-vm-tf-2.13.0

B. Connect
gcloud compute tpus tpu-vm ssh ean-column \
  --zone europe-west4-a

On Console, click the SSh next to the instance
This will take you direct to the instance terminal. Install packages here. Run scripts using python3 testl.py, unless 
you connect with jupyter lab
----------------



Approach 2: On console with SSH keys
1. Set up a Google Cloud project
2. Enable the Compute Engine and TPU APIs
3. Create a TPU VM
4. Connect to the TPU VM - connect  using the SSH option just next to the instance
5. Install Jupyter Lab
         pip install jupyterlab

6. Start Jupyter Lab
         jupyter lab --ip=0.0.0.0 --port=8888 --no-browser

7. Access Jupyter Lab - on local machine terminal
         gcloud compute ssh --project dl-market-predictions --zone europe-west4-a -- -L 8888:localhost:8888

8. Access Jupyter Lab in a web browser
         http://localhost:8888
That's it! You have now accessed a TPU VM using Google Cloud and are using Jupyter Lab on the TPU VM.

More info
1. https://zzzcode.ai/answer-question?id=15a78e83-a26a-4d9d-a161-40c7ba775aca




Approach c
1. Connect to the  Cloud TPU VM from the  Local terminal
------------
         gcloud compute tpus tpu-vm ssh avenirbold \
--zone europe-west4-a
------------
2. create a file
a. nano avenir_demo.py
b. Copy paste the python script and run
         python3 avenir_demo.py
3. That is it!! 

More info: 
1. https://github.com/GoogleCloudPlatform/cloud-shell-tutorials/blob/master/cloud-console-tutorials/cloud_tpu_quickstart/cloud_tpu_quickstart.md
2. https://github.com/GoogleCloudPlatform/cloud-shell-tutorials/blob/master/cloud-console-tutorials/cloud_tpu_quickstart/cloud_tpu_quickstart-en-GB.md
3. https://lightning.ai/docs/pytorch/1.4.5/advanced/tpu.html#:~:text=Colab%20is%20like%20a%20jupyter,research.google.com%2F.
4. BEST: https://zzzcode.ai/answer-question?id=15a78e83-a26a-4d9d-a161-40c7ba775aca
--------------------------------------


Using TPUs in Google Colab - First steps

1. Go to Colab
   First enter the Colab, make sure you specify the runtime environment. 
    a. Go to Runtime, click “Change Runtime Type”, and set the Hardware accelerator to “TPU”.
    b. Click 'connect' (on the right corner)


2. Check TPU Availability | configure TPU
   a. Ensure that TPU is available in  Colab environment.  You can check for TPU address / availability by running the 
       following code snippet:
------------
import tensorflow as tf
tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
print("TPU address:", tpu.master())
------------
    b. The above code will generate the  TPU address, which looks similar to:
                       TPU address: grpc://10.34.40.194:8470

    c. If the output shows a TPU address, it means that TPU is available in   Colab instance. If not, it means that TPU is 
       not available, and you will have to use CPU or GPU for computations. Remember, the TPU address is provided by the administrator 
       of the TPU cluster

    d. Once we have the TPU address, we can now assign it to the tpu_address variable  and define the TPU cluster 
------------
import tensorflow as tf

# Define TPU address
tpu_address = 'grpc://10.34.40.194:8470'  # Replace with your TPU address

# Create TPU cluster resolver
tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)

# Connect to the TPU
tf.config.experimental_connect_to_cluster(tpu_resolver)
tf.tpu.experimental.initialize_tpu_system(tpu_resolver)
------------
      e. Verify TPU Connection
         After connecting to the TPU,  verify the connection by printing the TPU topology using the code snipet below / The above code also 
         generates the topology, either way
------------
print('TPU:', tf.distribute.cluster_resolver.TPUClusterResolver().master())
print('TPU topology:', tf.tpu.experimental.initialize_tpu_system(tpu_resolver))
------------    
      f. The TPU topology will be similar to the following
                      <tensorflow.python.tpu.topology.Topology at 0x7b2a80bd6740>

      g. That's it. You have successfully connected to TPU Cloud instance. 

----------------------
More Information
1. https://cloud.google.com/tpu/docs/run-calculation-tensorflow


